{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начинаем работу с импортов всего, что нам пригодится:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "работаем мы сегодня с датасетом Digital Innovation Research Dataset (1983-2019) (https://data.mendeley.com/datasets/gpr2phd9mk/1) - списком публикаций по теме цифровых инноваций.\n",
    "\n",
    "из него нам понадобятся колонки с кратким содержанием и тегами, заданными авторами; извлечем все это в датафрейм и заодно заполним НаНы пустотами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital India is the dream project for the gov...</td>\n",
       "      <td>Chi-Square; Correlation; Cross-tab; Digitaliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Purpose: As various scholars have pointed out,...</td>\n",
       "      <td>Antecedents; Digital; Digital innovation manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Purpose: The purpose of this paper is to revie...</td>\n",
       "      <td>Digital innovation; Information technology; In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Purpose: Many start-ups are in search of coope...</td>\n",
       "      <td>Cooperation behaviour; Corporate start-up; Dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Purpose: Digital transformations are changing ...</td>\n",
       "      <td>Business processes; Conceptual modelling; Digi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Abstract                                       Author Keywords                  \n",
       "0  Digital India is the dream project for the gov...  Chi-Square; Correlation; Cross-tab; Digitaliza...\n",
       "1  Purpose: As various scholars have pointed out,...  Antecedents; Digital; Digital innovation manag...\n",
       "2  Purpose: The purpose of this paper is to revie...  Digital innovation; Information technology; In...\n",
       "3  Purpose: Many start-ups are in search of coope...  Cooperation behaviour; Corporate start-up; Dig...\n",
       "4  Purpose: Digital transformations are changing ...  Business processes; Conceptual modelling; Digi..."
      ]
     },
     "execution_count": 1370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = pd.read_csv('digital innovation dataset.csv', usecols = ['Abstract','Author Keywords'])\n",
    "data_1 = data_1.fillna('')\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "красивое. Выкинем отсюда все, что не имеет краткого содержания и/или авторских тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital India is the dream project for the gov...</td>\n",
       "      <td>Chi-Square; Correlation; Cross-tab; Digitaliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Purpose: As various scholars have pointed out,...</td>\n",
       "      <td>Antecedents; Digital; Digital innovation manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Purpose: The purpose of this paper is to revie...</td>\n",
       "      <td>Digital innovation; Information technology; In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Purpose: Many start-ups are in search of coope...</td>\n",
       "      <td>Cooperation behaviour; Corporate start-up; Dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Purpose: Digital transformations are changing ...</td>\n",
       "      <td>Business processes; Conceptual modelling; Digi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Abstract                                       Author Keywords                  \n",
       "0  Digital India is the dream project for the gov...  Chi-Square; Correlation; Cross-tab; Digitaliza...\n",
       "1  Purpose: As various scholars have pointed out,...  Antecedents; Digital; Digital innovation manag...\n",
       "2  Purpose: The purpose of this paper is to revie...  Digital innovation; Information technology; In...\n",
       "3  Purpose: Many start-ups are in search of coope...  Cooperation behaviour; Corporate start-up; Dig...\n",
       "4  Purpose: Digital transformations are changing ...  Business processes; Conceptual modelling; Digi..."
      ]
     },
     "execution_count": 1371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data_1[~(data_1['Abstract'] == '[No abstract available]') & ~(data_1['Author Keywords'] == '')]\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "немного поперебираем, чтобы посмотреть, сколько единиц нам нужно взять, чтобы получить где-то 3-5 тысяч токенов - токенизировать будем с помощью нлтк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4546"
      ]
     },
     "execution_count": 1372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counta = 0\n",
    "for i in data_clean.Abstract[:20]:\n",
    "    counta += len(nltk.word_tokenize(i))\n",
    "counta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ага, 20 штук подойдет, возьмем с запасом, чтобы потом можно было что-нибудь неподходящее удалить и токенов все равно было бы достаточно. Вытащим эти 20 штук в новый датафрейм, заодно обновим индексы, чтобы поправить пропавшие при очистке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital India is the dream project for the gov...</td>\n",
       "      <td>Chi-Square; Correlation; Cross-tab; Digitaliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Purpose: As various scholars have pointed out,...</td>\n",
       "      <td>Antecedents; Digital; Digital innovation manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Purpose: The purpose of this paper is to revie...</td>\n",
       "      <td>Digital innovation; Information technology; In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Purpose: Many start-ups are in search of coope...</td>\n",
       "      <td>Cooperation behaviour; Corporate start-up; Dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Purpose: Digital transformations are changing ...</td>\n",
       "      <td>Business processes; Conceptual modelling; Digi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Abstract                                       Author Keywords                  \n",
       "0  Digital India is the dream project for the gov...  Chi-Square; Correlation; Cross-tab; Digitaliza...\n",
       "1  Purpose: As various scholars have pointed out,...  Antecedents; Digital; Digital innovation manag...\n",
       "2  Purpose: The purpose of this paper is to revie...  Digital innovation; Information technology; In...\n",
       "3  Purpose: Many start-ups are in search of coope...  Cooperation behaviour; Corporate start-up; Dig...\n",
       "4  Purpose: Digital transformations are changing ...  Business processes; Conceptual modelling; Digi..."
      ]
     },
     "execution_count": 1373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_piece = data_clean.copy()[:20].reset_index(drop=True)\n",
    "data_piece.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "какой-то датафрейм у нас есть - но, очевидно, его никуда толком не скормить. Препроцессим!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с определения парочки нужных функций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "эта функция позволит нам разбить авторские теги из перечисления в список, заодно опустив регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_keywords_listify(some_string):\n",
    "    #input: string\n",
    "    #output: list of strings\n",
    "    stringlist = some_string.lower().split('; ')\n",
    "    return stringlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "эта функция позволит нам привести к приличному виду содержания: выкинуть оформительные \"цели работы, методология, задачи...\", чтобы они не всплыли потом в качестве ключевых слов, отбросить концевой копирайт и опустить регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_misc(some_string):\n",
    "    #input: string\n",
    "    #output: string\n",
    "    string_0 = some_string.replace('Purpose: ','').split(' ©')[0]\n",
    "    string_1 = string_0.replace('Design/methodology/approach: ','').replace('Findings: ','')\n",
    "    string_2 = string_1.replace('Originality/value: ','')\n",
    "    return string_2.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пройдемся обеими функциями по нашим данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_abstract = data_piece['Abstract'].map(delete_misc)\n",
    "data_piece['Abstract'] = clean_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_listified = data_piece['Author Keywords'].map(author_keywords_listify)\n",
    "data_piece['Author Keywords'] = keywords_listified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>digital india is the dream project for the gov...</td>\n",
       "      <td>[chi-square, correlation, cross-tab, digitaliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as various scholars have pointed out, the expo...</td>\n",
       "      <td>[antecedents, digital, digital innovation mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the purpose of this paper is to review and int...</td>\n",
       "      <td>[digital innovation, information technology, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many start-ups are in search of cooperation pa...</td>\n",
       "      <td>[cooperation behaviour, corporate start-up, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>digital transformations are changing society, ...</td>\n",
       "      <td>[business processes, conceptual modelling, dig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Abstract                                       Author Keywords                  \n",
       "0  digital india is the dream project for the gov...  [chi-square, correlation, cross-tab, digitaliz...\n",
       "1  as various scholars have pointed out, the expo...  [antecedents, digital, digital innovation mana...\n",
       "2  the purpose of this paper is to review and int...  [digital innovation, information technology, i...\n",
       "3  many start-ups are in search of cooperation pa...  [cooperation behaviour, corporate start-up, di...\n",
       "4  digital transformations are changing society, ...  [business processes, conceptual modelling, dig..."
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_piece.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "отлично! с этой проблемой разобрались, и теперь имеем нормальные содержания и списки авторских тегов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тем не менее, авторские теги это, конечно, хорошо - но никто не гарантирует, что они являются ключевыми словами, т.е. будут в содержании. Это надо проверить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_abstract(keyword_list, abstract):\n",
    "    #input: list of keywords, string\n",
    "    #output: list of keywords\n",
    "    removal_list = []\n",
    "    for keyword in keyword_list:\n",
    "        if keyword in abstract:\n",
    "            pass\n",
    "        else:\n",
    "            removal_list.append(keyword)\n",
    "    if bool(removal_list)==True:\n",
    "        new_keywords = [x for x in keyword_list if x not in removal_list]\n",
    "        removal_list = []\n",
    "        return new_keywords\n",
    "    else:\n",
    "        return keyword_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пройдемся этим по каждому ряду датафрейма, оставляя только те авторские теги, которые встречались в тексте; их добавим в список."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checking_list = []\n",
    "for row in range(len(data_piece)):\n",
    "    checking_list.append(check_abstract(data_piece['Author Keywords'][row], data_piece['Abstract'][row]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "из первого ряда вообще никакие авторские теги не являются ключевыми словами - список пустой. Удаляем его, а оставшиеся 19 штук пересохраняем в финальный красивый датафрейм. С ним мы и будем дальше работать - так что снова обновим индексы, а то мало ли что мы там удаляли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data_piece.drop(0).reset_index(drop=True)\n",
    "data['Author Keywords'] = checking_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as various scholars have pointed out, the expo...</td>\n",
       "      <td>[digital, innovation, outcomes, processes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the purpose of this paper is to review and int...</td>\n",
       "      <td>[information technology, innovation, literatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many start-ups are in search of cooperation pa...</td>\n",
       "      <td>[start-up cooperation, start-up performance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digital transformations are changing society, ...</td>\n",
       "      <td>[business processes, innovation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the article identifies how collaborations with...</td>\n",
       "      <td>[digital innovation, industry 4.0, innovation ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Abstract                                       Author Keywords                  \n",
       "0  as various scholars have pointed out, the expo...         [digital, innovation, outcomes, processes]\n",
       "1  the purpose of this paper is to review and int...  [information technology, innovation, literatur...\n",
       "2  many start-ups are in search of cooperation pa...       [start-up cooperation, start-up performance]\n",
       "3  digital transformations are changing society, ...                   [business processes, innovation]\n",
       "4  the article identifies how collaborations with...  [digital innovation, industry 4.0, innovation ..."
      ]
     },
     "execution_count": 1382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "почти готово! осталось только лемматизировать - желательно и то, и другое, потому что искать нелемматизованные теги в лемматизованном тексте было бы не особо эффективно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "так как мы работаем с английскими текстами (слава богу), для лемматизации можем использовать spacy с токенизацией через nltk - возьмем лучшее из обоих миров! И очистим от пунктуации заодно.\n",
    "\n",
    "работать будем в две функции - первая, маленькая вспомогательная, делает основную работу по лемматизации текста; вторая, оберточная, определяет, дали ей содержание или список тегов, и в зависимости от этого формирует список-выдачу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lem_helper(text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    tokens = list(filter(lambda token: token not in string.punctuation, tokenized))\n",
    "    doc = nlp(' '.join(tokens))\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "    \n",
    "def lemmatization(obj, flag):\n",
    "    all_lems = []\n",
    "    if flag == 'abstract':\n",
    "        all_lems = lem_helper(obj)       \n",
    "    elif flag == 'keywords':\n",
    "        for el in obj:\n",
    "            all_lems.append(lem_helper(el))\n",
    "    return all_lems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data - drive motion correction', 'digital innovation', 'pet', 'real - time']"
      ]
     },
     "execution_count": 1384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization(data['Author Keywords'][7], flag='keywords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ах, как печально. Спейси засчитывает дефис за разделитель слов! Это сильно портит нам настроение. Что будем делать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ну, например, проконсультируемся с его документацией (https://spacy.io/usage/linguistic-features) - а если она даст нам даже кусок кода, которым можно исправить методы определения границ слов, будет вообще прекрасно. Даст же?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER\n",
    "from spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "infixes = (\n",
    "    LIST_ELLIPSES\n",
    "    + LIST_ICONS\n",
    "    + [\n",
    "        r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
    "        r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n",
    "            al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
    "        ),\n",
    "        r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
    "        r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
    "    ]\n",
    ")\n",
    "\n",
    "infix_re = compile_infix_regex(infixes)\n",
    "nlp.tokenizer.infix_finditer = infix_re.finditer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data-driven motion correction', 'digital innovation', 'pet', 'real-time']"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization(data['Author Keywords'][7], flag='keywords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "боже, храни эту библиотеку и авторов ее документации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "пойдемте все наконец лемматизируем и начнем работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['abstract_lemmatized'] = data['Abstract'].map(lambda p: lemmatization(p, flag='abstract'))\n",
    "data['Author_keys_lemmatized'] = data['Author Keywords'].map(lambda p: lemmatization(p, flag='keywords'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>abstract_lemmatized</th>\n",
       "      <th>Author_keys_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as various scholars have pointed out, the expo...</td>\n",
       "      <td>[digital, innovation, outcomes, processes]</td>\n",
       "      <td>as various scholar have point out the exponent...</td>\n",
       "      <td>[digital, innovation, outcome, process]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the purpose of this paper is to review and int...</td>\n",
       "      <td>[information technology, innovation, literatur...</td>\n",
       "      <td>the purpose of this paper be to review and int...</td>\n",
       "      <td>[information technology, innovation, literatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many start-ups are in search of cooperation pa...</td>\n",
       "      <td>[start-up cooperation, start-up performance]</td>\n",
       "      <td>many start-up be in search of cooperation part...</td>\n",
       "      <td>[start-up cooperation, start-up performance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digital transformations are changing society, ...</td>\n",
       "      <td>[business processes, innovation]</td>\n",
       "      <td>digital transformation be change society and t...</td>\n",
       "      <td>[business process, innovation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the article identifies how collaborations with...</td>\n",
       "      <td>[digital innovation, industry 4.0, innovation ...</td>\n",
       "      <td>the article identify how collaboration with st...</td>\n",
       "      <td>[digital innovation, industry 4.0, innovation ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Abstract                                       Author Keywords                                  abstract_lemmatized                               Author_keys_lemmatized              \n",
       "0  as various scholars have pointed out, the expo...         [digital, innovation, outcomes, processes]  as various scholar have point out the exponent...            [digital, innovation, outcome, process]\n",
       "1  the purpose of this paper is to review and int...  [information technology, innovation, literatur...  the purpose of this paper be to review and int...  [information technology, innovation, literatur...\n",
       "2  many start-ups are in search of cooperation pa...       [start-up cooperation, start-up performance]  many start-up be in search of cooperation part...       [start-up cooperation, start-up performance]\n",
       "3  digital transformations are changing society, ...                   [business processes, innovation]  digital transformation be change society and t...                     [business process, innovation]\n",
       "4  the article identifies how collaborations with...  [digital innovation, industry 4.0, innovation ...  the article identify how collaboration with st...  [digital innovation, industry 4.0, innovation ..."
      ]
     },
     "execution_count": 1388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "препроц закончен!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. own keywords and gold standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начинаем медленную и печальную работу по ручной разметке. Я закомментировала эту ячейку, но поверьте - она выдала мне содержания всех наших образцов, и я подобрала ко всем теги. Ух."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each in data['Abstract']:\n",
    "    #print(each)\n",
    "    #print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_keys = []\n",
    "own_keys.append(['innovation', 'business process', 'innovation input', 'innovation process', 'innovation outcome', 'digital innovation'])\n",
    "own_keys.append(['information technology', 'literature review', 'innovation'])\n",
    "own_keys.append(['cooperation', 'start-up cooperation', 'cooperation behavior', 'incumbent firms', 'cooperation model'])\n",
    "own_keys.append(['digital change', 'innovation', 'cooperative model'])\n",
    "own_keys.append(['digital innovation', 'r&d collaboration' , 'open innovation', 'industry 4.0', 'innovation practice', 'startup'])\n",
    "own_keys.append(['technology development in agriculture', 'agriculture', 'smart farm', 'digital innovation', 'digiware', 'advisory service', 'farm management'])\n",
    "own_keys.append(['public welfare', 'digital innovation', 'environmental public welfare project'])\n",
    "own_keys.append(['data-driven innovation', 'hardware-driven motion correction','data-driven motion correction', 'ddmc', 'real-time ddmc', 'pet', 'motion correction'])\n",
    "own_keys.append(['communication technology', 'computer literacy', 'digital innovation in teaching', 'educational process', 'digitally mature school project'])\n",
    "own_keys.append(['mental disorder', 'mental health', 'mental health care', 'low resource setting', 'digital intervention'])\n",
    "own_keys.append(['ethical issue', 'ethical research', 'mhealth', 'autonomy'])\n",
    "own_keys.append(['healthcare provision', 'healthcare', 'health data', 'europe', 'cooperation', 'digital innovation'])\n",
    "own_keys.append(['automation', 'data science', 'journalistic field', 'technological field', 'digital innovation', 'field theory'])\n",
    "own_keys.append(['technology design', 'empowerment', 'participatory practice', 'social innovation'])\n",
    "own_keys.append(['business model', 'incumbent', 'digital innovation', 'digital technology', 'dts', 'incumbent firm'])\n",
    "own_keys.append(['crowdsource', 'digital innovation ecosystem', 'management field'])\n",
    "own_keys.append(['information technology', 'it', 'patent invention', 'innovation process', 'knowledge recombinant intensity', 'knowledge recombinant diversity'])\n",
    "own_keys.append(['digital innovation', 'knowledge integration', 'cross-domain collaboration', 'knowledge domain', 'coordination'])\n",
    "own_keys.append(['operating model', 'digital innovation', 'fuel loyalty program', 'loyalty program platform', 'slpp'])\n",
    "assert len(own_keys) == len(data)\n",
    "data['own_keywords'] = list(map(lambda p: lemmatization(p, flag='keywords'), own_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "убедившись, что мы не пропустили ничего и длина списка тегов равна длине датафрейма, составляем золотой стандарт - совокупность наших и авторских тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_standard = []\n",
    "for num in range(len(data)):\n",
    "    g_standard.append(set(data['Author_keys_lemmatized'][num]).union(set(data['own_keywords'][num])))\n",
    "data['gold_standard'] = [list(x) for x in g_standard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>abstract_lemmatized</th>\n",
       "      <th>Author_keys_lemmatized</th>\n",
       "      <th>own_keywords</th>\n",
       "      <th>gold_standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as various scholars have pointed out, the expo...</td>\n",
       "      <td>[digital, innovation, outcomes, processes]</td>\n",
       "      <td>as various scholar have point out the exponent...</td>\n",
       "      <td>[digital, innovation, outcome, process]</td>\n",
       "      <td>[innovation, business process, innovation inpu...</td>\n",
       "      <td>[innovation, outcome, digital, innovation inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the purpose of this paper is to review and int...</td>\n",
       "      <td>[information technology, innovation, literatur...</td>\n",
       "      <td>the purpose of this paper be to review and int...</td>\n",
       "      <td>[information technology, innovation, literatur...</td>\n",
       "      <td>[information technology, literature review, in...</td>\n",
       "      <td>[innovation, information technology, literatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many start-ups are in search of cooperation pa...</td>\n",
       "      <td>[start-up cooperation, start-up performance]</td>\n",
       "      <td>many start-up be in search of cooperation part...</td>\n",
       "      <td>[start-up cooperation, start-up performance]</td>\n",
       "      <td>[cooperation, start-up cooperation, cooperatio...</td>\n",
       "      <td>[cooperation, start-up performance, start-up c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digital transformations are changing society, ...</td>\n",
       "      <td>[business processes, innovation]</td>\n",
       "      <td>digital transformation be change society and t...</td>\n",
       "      <td>[business process, innovation]</td>\n",
       "      <td>[digital change, innovation, cooperative model]</td>\n",
       "      <td>[business process, innovation, digital change,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the article identifies how collaborations with...</td>\n",
       "      <td>[digital innovation, industry 4.0, innovation ...</td>\n",
       "      <td>the article identify how collaboration with st...</td>\n",
       "      <td>[digital innovation, industry 4.0, innovation ...</td>\n",
       "      <td>[digital innovation, r d collaboration, open i...</td>\n",
       "      <td>[innovation practice, innovation ecosystem, di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Abstract                                       Author Keywords                                  abstract_lemmatized                               Author_keys_lemmatized                                  own_keywords                                      gold_standard                   \n",
       "0  as various scholars have pointed out, the expo...         [digital, innovation, outcomes, processes]  as various scholar have point out the exponent...            [digital, innovation, outcome, process]  [innovation, business process, innovation inpu...  [innovation, outcome, digital, innovation inpu...\n",
       "1  the purpose of this paper is to review and int...  [information technology, innovation, literatur...  the purpose of this paper be to review and int...  [information technology, innovation, literatur...  [information technology, literature review, in...  [innovation, information technology, literatur...\n",
       "2  many start-ups are in search of cooperation pa...       [start-up cooperation, start-up performance]  many start-up be in search of cooperation part...       [start-up cooperation, start-up performance]  [cooperation, start-up cooperation, cooperatio...  [cooperation, start-up performance, start-up c...\n",
       "3  digital transformations are changing society, ...                   [business processes, innovation]  digital transformation be change society and t...                     [business process, innovation]    [digital change, innovation, cooperative model]  [business process, innovation, digital change,...\n",
       "4  the article identifies how collaborations with...  [digital innovation, industry 4.0, innovation ...  the article identify how collaboration with st...  [digital innovation, industry 4.0, innovation ...  [digital innovation, r d collaboration, open i...  [innovation practice, innovation ecosystem, di..."
      ]
     },
     "execution_count": 1392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "бинго."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. autokeywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "наш первый кандидат - РАКЕ, который я буду писать так, потому что мне лень переключать раскладку. Скормим ему лемматизированные содержания без стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RAKE\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rake_kw = []\n",
    "for num in range(len(data)):\n",
    "    rake_kw.append([x[0] for x in rake.run(data['abstract_lemmatized'].values[num], minCharacters=2, maxWords=3, minFrequency=1.5)])\n",
    "data['RAKE'] = rake_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textrank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "следующий кандидат - textrank. Механизм работы с ним примерно тот же - передать стоп-слова и лемматизированный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textrank = []\n",
    "for num in range(len(data)):\n",
    "    textrank.append([x[0] for x in keywords.keywords(data['abstract_lemmatized'].values[num], language='english', additional_stopwords=stop, scores=True)])\n",
    "data['textrank'] = textrank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а кто же это такой? Да это же УАКЕ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/LIAAD/yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "yake_kw_extractor = yake.KeywordExtractor(lan='en', dedupLim=0.95, features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yake_kw = []\n",
    "for num in range(len(data)):\n",
    "    keywords = yake_kw_extractor.extract_keywords(data['abstract_lemmatized'].values[num])\n",
    "    yake_kw.append([x[0].lower() for x in keywords])\n",
    "data['YAKE'] = yake_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы будем делать частеречные шаблоны? Как и всегда - с помощью какой-нибудь маленькой, но трудолюбивой функции, которая нам все сделает. Правда, написать ее придется нам самим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Механизм простой, как банка - токенизируем переданные слова, определяем их часть речи, склеиваем в сочетания частей речи, определяемых универсальной системой тегов, чтобы красивее было; сет нам нужен, чтобы не повторяться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "def pos_helper(wordlist):\n",
    "    pos_set = set()\n",
    "    pos_tokens = [word_tokenize(x) for x in wordlist]\n",
    "    for y in pos_tokens:\n",
    "        pos_set.add('+'.join([x[1] for x in nltk.pos_tag(y, tagset='universal')]))\n",
    "    return pos_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mold'] = data['gold_standard'].map(pos_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>abstract_lemmatized</th>\n",
       "      <th>Author_keys_lemmatized</th>\n",
       "      <th>own_keywords</th>\n",
       "      <th>gold_standard</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>textrank</th>\n",
       "      <th>YAKE</th>\n",
       "      <th>mold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as various scholars have pointed out, the expo...</td>\n",
       "      <td>[digital, innovation, outcomes, processes]</td>\n",
       "      <td>as various scholar have point out the exponent...</td>\n",
       "      <td>[digital, innovation, outcome, process]</td>\n",
       "      <td>[innovation, business process, innovation inpu...</td>\n",
       "      <td>[innovation, outcome, digital, innovation inpu...</td>\n",
       "      <td>[digital technology, purpose]</td>\n",
       "      <td>[exponential growth, compress anticipate, inno...</td>\n",
       "      <td>[special issue paper, special issue accord, sp...</td>\n",
       "      <td>{NOUN, NOUN+NOUN, ADJ+NOUN}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the purpose of this paper is to review and int...</td>\n",
       "      <td>[information technology, innovation, literatur...</td>\n",
       "      <td>the purpose of this paper be to review and int...</td>\n",
       "      <td>[information technology, innovation, literatur...</td>\n",
       "      <td>[information technology, literature review, in...</td>\n",
       "      <td>[innovation, information technology, literatur...</td>\n",
       "      <td>[group level, innovation, role, individual, to...</td>\n",
       "      <td>[publish, integrate, integrative, integration,...</td>\n",
       "      <td>[research publish focus, support innovation pu...</td>\n",
       "      <td>{NOUN, NOUN+NOUN}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many start-ups are in search of cooperation pa...</td>\n",
       "      <td>[start-up cooperation, start-up performance]</td>\n",
       "      <td>many start-up be in search of cooperation part...</td>\n",
       "      <td>[start-up cooperation, start-up performance]</td>\n",
       "      <td>[cooperation, start-up cooperation, cooperatio...</td>\n",
       "      <td>[cooperation, start-up performance, start-up c...</td>\n",
       "      <td>[cooperation behavior, start-, use, build, per...</td>\n",
       "      <td>[study, cooperation, base, start, factor, scal...</td>\n",
       "      <td>[past study identify, lack empirical research,...</td>\n",
       "      <td>{NOUN, NOUN+NOUN, ADJ+NOUN}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digital transformations are changing society, ...</td>\n",
       "      <td>[business processes, innovation]</td>\n",
       "      <td>digital transformation be change society and t...</td>\n",
       "      <td>[business process, innovation]</td>\n",
       "      <td>[digital change, innovation, cooperative model]</td>\n",
       "      <td>[business process, innovation, digital change,...</td>\n",
       "      <td>[certain level, case company, change, digitali...</td>\n",
       "      <td>[change society, digital transformation, accor...</td>\n",
       "      <td>[process maturity level, process maturity mode...</td>\n",
       "      <td>{NOUN, NOUN+NOUN, ADJ+NOUN}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the article identifies how collaborations with...</td>\n",
       "      <td>[digital innovation, industry 4.0, innovation ...</td>\n",
       "      <td>the article identify how collaboration with st...</td>\n",
       "      <td>[digital innovation, industry 4.0, innovation ...</td>\n",
       "      <td>[digital innovation, r d collaboration, open i...</td>\n",
       "      <td>[innovation practice, innovation ecosystem, di...</td>\n",
       "      <td>[startup, collaboration, industry 4, brazil]</td>\n",
       "      <td>[article identify, low maturity stage, theoret...</td>\n",
       "      <td>[international innovation center, open innovat...</td>\n",
       "      <td>{NOUN, NOUN+NOUN, ADJ+NOUN, NOUN+NOUN+NOUN, NO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Abstract                                       Author Keywords                                  abstract_lemmatized                               Author_keys_lemmatized                                  own_keywords                                      gold_standard                                           RAKE                                             textrank                                             YAKE                                               mold                       \n",
       "0  as various scholars have pointed out, the expo...         [digital, innovation, outcomes, processes]  as various scholar have point out the exponent...            [digital, innovation, outcome, process]  [innovation, business process, innovation inpu...  [innovation, outcome, digital, innovation inpu...                      [digital technology, purpose]  [exponential growth, compress anticipate, inno...  [special issue paper, special issue accord, sp...                        {NOUN, NOUN+NOUN, ADJ+NOUN}\n",
       "1  the purpose of this paper is to review and int...  [information technology, innovation, literatur...  the purpose of this paper be to review and int...  [information technology, innovation, literatur...  [information technology, literature review, in...  [innovation, information technology, literatur...  [group level, innovation, role, individual, to...  [publish, integrate, integrative, integration,...  [research publish focus, support innovation pu...                                  {NOUN, NOUN+NOUN}\n",
       "2  many start-ups are in search of cooperation pa...       [start-up cooperation, start-up performance]  many start-up be in search of cooperation part...       [start-up cooperation, start-up performance]  [cooperation, start-up cooperation, cooperatio...  [cooperation, start-up performance, start-up c...  [cooperation behavior, start-, use, build, per...  [study, cooperation, base, start, factor, scal...  [past study identify, lack empirical research,...                        {NOUN, NOUN+NOUN, ADJ+NOUN}\n",
       "3  digital transformations are changing society, ...                   [business processes, innovation]  digital transformation be change society and t...                     [business process, innovation]    [digital change, innovation, cooperative model]  [business process, innovation, digital change,...  [certain level, case company, change, digitali...  [change society, digital transformation, accor...  [process maturity level, process maturity mode...                        {NOUN, NOUN+NOUN, ADJ+NOUN}\n",
       "4  the article identifies how collaborations with...  [digital innovation, industry 4.0, innovation ...  the article identify how collaboration with st...  [digital innovation, industry 4.0, innovation ...  [digital innovation, r d collaboration, open i...  [innovation practice, innovation ecosystem, di...       [startup, collaboration, industry 4, brazil]  [article identify, low maturity stage, theoret...  [international innovation center, open innovat...  {NOUN, NOUN+NOUN, ADJ+NOUN, NOUN+NOUN+NOUN, NO..."
      ]
     },
     "execution_count": 1402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "отлично, есть молды (шаблоны) частеречных сочетаний - для каждого текста определенные относительно золотого стандарта для этого текста. Но что будет, если определять их относительно _всех золотых стандартов_, которые мы встретили в выборке? Это ведь все научные статьи, еще и по одной и той же теме. Но все авторские теги создавались разными авторами...\n",
    "\n",
    "посмотрим. Для того, чтобы посмотреть, сделаем общий сет всех частеречных сочетаний, которые встретились в нашей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ',\n",
       " 'ADJ+ADJ+NOUN+NOUN',\n",
       " 'ADJ+NOUN',\n",
       " 'ADJ+NOUN+ADP+NOUN',\n",
       " 'ADJ+NOUN+NOUN',\n",
       " 'ADV+ADJ+NOUN+NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN+NOUN',\n",
       " 'NOUN+NOUN+ADP+NOUN',\n",
       " 'NOUN+NOUN+NOUN',\n",
       " 'NOUN+NUM',\n",
       " 'NOUN+VERB',\n",
       " 'PRON'}"
      ]
     },
     "execution_count": 1403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mold_set = set()\n",
    "for num in range(len(data)):\n",
    "    full_mold_set |= data['mold'][num]\n",
    "full_mold_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вот и ладушки. пойдемте теперь с помощью этих молдов фильтровать выдачи моделек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как мы будем это делать? все так же, все так же..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_helper(dataframe, model):\n",
    "    molded_loc = []\n",
    "    molded_full = []\n",
    "    for num in range(len(dataframe)):\n",
    "        molded_loc_num = []\n",
    "        molded_full_num = []\n",
    "        for keywords in dataframe[model][num]:\n",
    "            pos_tokens = word_tokenize(keywords)\n",
    "            tag_group = '+'.join([x[1] for x in nltk.pos_tag(pos_tokens, tagset='universal')])\n",
    "            if tag_group in dataframe['mold'][num]:\n",
    "                molded_loc_num.append(keywords)\n",
    "                molded_full_num.append(keywords)\n",
    "            elif tag_group in full_mold_set:\n",
    "                molded_full_num.append(keywords)         \n",
    "        molded_loc.append(molded_loc_num)\n",
    "        molded_full.append(molded_full_num)\n",
    "    return molded_loc, molded_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "локальный молд = частеречные сочетания, встреченные в золотом стандарте конкретного текста, с которым мы сейчас работаем; полный молд = все частеречные сочетания, встреченные в золотых стандартах выборки. Обрабатываем все выдачи моделек и пропускаем дальше только тех кандидатов, которые подходят под наши молды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.assign(RAKE_molded_loc = compare_helper(data, 'RAKE')[0],\n",
    "            RAKE_molded_full = compare_helper(data, 'RAKE')[1],\n",
    "            YAKE_molded_loc = compare_helper(data, 'YAKE')[0],\n",
    "            YAKE_molded_full = compare_helper(data, 'YAKE')[1],\n",
    "            textrank_molded_loc = compare_helper(data, 'textrank')[0],\n",
    "            textrank_molded_full = compare_helper(data, 'textrank')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>abstract_lemmatized</th>\n",
       "      <th>Author_keys_lemmatized</th>\n",
       "      <th>own_keywords</th>\n",
       "      <th>gold_standard</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>textrank</th>\n",
       "      <th>YAKE</th>\n",
       "      <th>mold</th>\n",
       "      <th>RAKE_molded_loc</th>\n",
       "      <th>RAKE_molded_full</th>\n",
       "      <th>YAKE_molded_loc</th>\n",
       "      <th>YAKE_molded_full</th>\n",
       "      <th>textrank_molded_loc</th>\n",
       "      <th>textrank_molded_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as various scholars have pointed out, the expo...</td>\n",
       "      <td>[digital, innovation, outcomes, processes]</td>\n",
       "      <td>as various scholar have point out the exponent...</td>\n",
       "      <td>[digital, innovation, outcome, process]</td>\n",
       "      <td>[innovation, business process, innovation inpu...</td>\n",
       "      <td>[innovation, outcome, digital, innovation inpu...</td>\n",
       "      <td>[digital technology, purpose]</td>\n",
       "      <td>[exponential growth, compress anticipate, inno...</td>\n",
       "      <td>[special issue paper, special issue accord, sp...</td>\n",
       "      <td>{NOUN, NOUN+NOUN, ADJ+NOUN}</td>\n",
       "      <td>[digital technology, purpose]</td>\n",
       "      <td>[digital technology, purpose]</td>\n",
       "      <td>[special issue, digital technology, innovation...</td>\n",
       "      <td>[special issue paper, special issue accord, sp...</td>\n",
       "      <td>[exponential growth, compress anticipate, inno...</td>\n",
       "      <td>[exponential growth, compress anticipate, inno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the purpose of this paper is to review and int...</td>\n",
       "      <td>[information technology, innovation, literatur...</td>\n",
       "      <td>the purpose of this paper be to review and int...</td>\n",
       "      <td>[information technology, innovation, literatur...</td>\n",
       "      <td>[information technology, literature review, in...</td>\n",
       "      <td>[innovation, information technology, literatur...</td>\n",
       "      <td>[group level, innovation, role, individual, to...</td>\n",
       "      <td>[publish, integrate, integrative, integration,...</td>\n",
       "      <td>[research publish focus, support innovation pu...</td>\n",
       "      <td>{NOUN, NOUN+NOUN}</td>\n",
       "      <td>[group level, innovation, role, topic]</td>\n",
       "      <td>[group level, innovation, role, individual, to...</td>\n",
       "      <td>[innovation publish, support innovation, group...</td>\n",
       "      <td>[support innovation publish, information syste...</td>\n",
       "      <td>[publish, integrate, integration, research, st...</td>\n",
       "      <td>[publish, integrate, integrative, integration,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many start-ups are in search of cooperation pa...</td>\n",
       "      <td>[start-up cooperation, start-up performance]</td>\n",
       "      <td>many start-up be in search of cooperation part...</td>\n",
       "      <td>[start-up cooperation, start-up performance]</td>\n",
       "      <td>[cooperation, start-up cooperation, cooperatio...</td>\n",
       "      <td>[cooperation, start-up performance, start-up c...</td>\n",
       "      <td>[cooperation behavior, start-, use, build, per...</td>\n",
       "      <td>[study, cooperation, base, start, factor, scal...</td>\n",
       "      <td>[past study identify, lack empirical research,...</td>\n",
       "      <td>{NOUN, NOUN+NOUN, ADJ+NOUN}</td>\n",
       "      <td>[cooperation behavior, start-, use, build, per...</td>\n",
       "      <td>[cooperation behavior, start-, use, build, per...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[past study identify, past study focus, measur...</td>\n",
       "      <td>[study, cooperation, base, start, factor, scal...</td>\n",
       "      <td>[study, cooperation, base, start, factor, scal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digital transformations are changing society, ...</td>\n",
       "      <td>[business processes, innovation]</td>\n",
       "      <td>digital transformation be change society and t...</td>\n",
       "      <td>[business process, innovation]</td>\n",
       "      <td>[digital change, innovation, cooperative model]</td>\n",
       "      <td>[business process, innovation, digital change,...</td>\n",
       "      <td>[certain level, case company, change, digitali...</td>\n",
       "      <td>[change society, digital transformation, accor...</td>\n",
       "      <td>[process maturity level, process maturity mode...</td>\n",
       "      <td>{NOUN, NOUN+NOUN, ADJ+NOUN}</td>\n",
       "      <td>[certain level, case company, change, digitali...</td>\n",
       "      <td>[certain level, case company, change, digitali...</td>\n",
       "      <td>[process maturity, innovation level, business ...</td>\n",
       "      <td>[process maturity level, process maturity mode...</td>\n",
       "      <td>[change society, digital transformation, accor...</td>\n",
       "      <td>[change society, digital transformation, accor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the article identifies how collaborations with...</td>\n",
       "      <td>[digital innovation, industry 4.0, innovation ...</td>\n",
       "      <td>the article identify how collaboration with st...</td>\n",
       "      <td>[digital innovation, industry 4.0, innovation ...</td>\n",
       "      <td>[digital innovation, r d collaboration, open i...</td>\n",
       "      <td>[innovation practice, innovation ecosystem, di...</td>\n",
       "      <td>[startup, collaboration, industry 4, brazil]</td>\n",
       "      <td>[article identify, low maturity stage, theoret...</td>\n",
       "      <td>[international innovation center, open innovat...</td>\n",
       "      <td>{NOUN, NOUN+NOUN, ADJ+NOUN, NOUN+NOUN+NOUN, NO...</td>\n",
       "      <td>[startup, collaboration, industry 4, brazil]</td>\n",
       "      <td>[startup, collaboration, industry 4, brazil]</td>\n",
       "      <td>[government development agency, company univer...</td>\n",
       "      <td>[international innovation center, open innovat...</td>\n",
       "      <td>[use]</td>\n",
       "      <td>[article identify, low maturity stage, theoret...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Abstract                                       Author Keywords                                  abstract_lemmatized                               Author_keys_lemmatized                                  own_keywords                                      gold_standard                                           RAKE                                             textrank                                             YAKE                                               mold                                         RAKE_molded_loc                                    RAKE_molded_full                                   YAKE_molded_loc                                    YAKE_molded_full                                 textrank_molded_loc                                textrank_molded_full               \n",
       "0  as various scholars have pointed out, the expo...         [digital, innovation, outcomes, processes]  as various scholar have point out the exponent...            [digital, innovation, outcome, process]  [innovation, business process, innovation inpu...  [innovation, outcome, digital, innovation inpu...                      [digital technology, purpose]  [exponential growth, compress anticipate, inno...  [special issue paper, special issue accord, sp...                        {NOUN, NOUN+NOUN, ADJ+NOUN}                      [digital technology, purpose]                      [digital technology, purpose]  [special issue, digital technology, innovation...  [special issue paper, special issue accord, sp...  [exponential growth, compress anticipate, inno...  [exponential growth, compress anticipate, inno...\n",
       "1  the purpose of this paper is to review and int...  [information technology, innovation, literatur...  the purpose of this paper be to review and int...  [information technology, innovation, literatur...  [information technology, literature review, in...  [innovation, information technology, literatur...  [group level, innovation, role, individual, to...  [publish, integrate, integrative, integration,...  [research publish focus, support innovation pu...                                  {NOUN, NOUN+NOUN}             [group level, innovation, role, topic]  [group level, innovation, role, individual, to...  [innovation publish, support innovation, group...  [support innovation publish, information syste...  [publish, integrate, integration, research, st...  [publish, integrate, integrative, integration,...\n",
       "2  many start-ups are in search of cooperation pa...       [start-up cooperation, start-up performance]  many start-up be in search of cooperation part...       [start-up cooperation, start-up performance]  [cooperation, start-up cooperation, cooperatio...  [cooperation, start-up performance, start-up c...  [cooperation behavior, start-, use, build, per...  [study, cooperation, base, start, factor, scal...  [past study identify, lack empirical research,...                        {NOUN, NOUN+NOUN, ADJ+NOUN}  [cooperation behavior, start-, use, build, per...  [cooperation behavior, start-, use, build, per...                                                 []  [past study identify, past study focus, measur...  [study, cooperation, base, start, factor, scal...  [study, cooperation, base, start, factor, scal...\n",
       "3  digital transformations are changing society, ...                   [business processes, innovation]  digital transformation be change society and t...                     [business process, innovation]    [digital change, innovation, cooperative model]  [business process, innovation, digital change,...  [certain level, case company, change, digitali...  [change society, digital transformation, accor...  [process maturity level, process maturity mode...                        {NOUN, NOUN+NOUN, ADJ+NOUN}  [certain level, case company, change, digitali...  [certain level, case company, change, digitali...  [process maturity, innovation level, business ...  [process maturity level, process maturity mode...  [change society, digital transformation, accor...  [change society, digital transformation, accor...\n",
       "4  the article identifies how collaborations with...  [digital innovation, industry 4.0, innovation ...  the article identify how collaboration with st...  [digital innovation, industry 4.0, innovation ...  [digital innovation, r d collaboration, open i...  [innovation practice, innovation ecosystem, di...       [startup, collaboration, industry 4, brazil]  [article identify, low maturity stage, theoret...  [international innovation center, open innovat...  {NOUN, NOUN+NOUN, ADJ+NOUN, NOUN+NOUN+NOUN, NO...       [startup, collaboration, industry 4, brazil]       [startup, collaboration, industry 4, brazil]  [government development agency, company univer...  [international innovation center, open innovat...                                              [use]  [article identify, low maturity stage, theoret..."
      ]
     },
     "execution_count": 1406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "все, мы собрали полный фрейм данных. Оставляем этот несчастный датафрейм в покое и идем оценивать, а насколько мы вообще хорошо сработали."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как тяжело смотреть на губы, которые не можешь поцеловать, и метрики, которые не можешь импортировать из sklearn. Пойдем тогда обратимся к формальному определению полноты и точности, чтобы понять, какие именно вещи мы хотим оценивать в задаче выбора ключевых слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#how many relevant items are selected?\n",
    "#selected relevant items/all relevant items\n",
    "def recall_metric(dataframe,model):\n",
    "    recall_kws = []\n",
    "    for num in range(len(dataframe)):\n",
    "        recall_kws.append(len([x for x in dataframe[model][num] if x in dataframe['gold_standard'][num]])/len(dataframe['gold_standard'][num]))\n",
    "    return recall_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many selected items are relevant?\n",
    "#relevant selected items/all selected items\n",
    "def precision_metric(dataframe,model):\n",
    "    prec_kws = []\n",
    "    for num in range(len(dataframe)):\n",
    "        if len(dataframe[model][num]) == 0:\n",
    "            prec_kws.append(float(0))\n",
    "        else:\n",
    "            prec_kws.append(len([x for x in dataframe[model][num] if x in dataframe['gold_standard'][num]])/len(dataframe[model][num]))\n",
    "    return prec_kws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "да-да, подстраховались, чтобы не делить на ноль. Полноте это не надо - там в делителе длина золотого стандарта, а он нигде не пустой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "новый датафрейм! О-бо-жаю датафреймы. Засунем сюда оценки полноты и точности всех трех наших моделек - без учета частей речи, с учетом локальных частеречных молдов и с учетом полных частеречных молдов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_frame = pd.DataFrame({'RAKE_recall': recall_metric(data, 'RAKE'),\n",
    "                            'RAKE_precision': precision_metric(data, 'RAKE'),\n",
    "                            'RAKE_molded_loc_precision': precision_metric(data, 'RAKE_molded_loc'),\n",
    "                            'RAKE_molded_full_precision': precision_metric(data, 'RAKE_molded_full'),\n",
    "                            'YAKE_recall': recall_metric(data, 'YAKE'),\n",
    "                            'YAKE_precision': precision_metric(data, 'YAKE'),\n",
    "                            'YAKE_molded_loc_precision': precision_metric(data, 'YAKE_molded_loc'),\n",
    "                            'YAKE_molded_full_precision': precision_metric(data, 'YAKE_molded_full'),\n",
    "                            'textrank_recall': recall_metric(data, 'textrank'),\n",
    "                            'textrank_precision': precision_metric(data, 'textrank'),\n",
    "                            'textrank_molded_loc_precision': precision_metric(data, 'textrank_molded_loc'),\n",
    "                            'textrank_molded_full_precision': precision_metric(data, 'textrank_molded_full')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не позволяя себе ни минуты на отдых, идем вычислять для каждого случая ф-число - снова подстраховавшись, чтобы не поделить на ноль, - и вставляем в тот же датафрейм на удачные места."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2*recall*precision)/recall+precision\n",
    "def f_score_metric(dataframe, model):\n",
    "    f_score_list = []\n",
    "    f_score_list_loc = []\n",
    "    f_score_list_full = []\n",
    "    for num in range(len(dataframe)):\n",
    "        sum_metrics = float(dataframe[f'{model}_recall'][num])+float(dataframe[f'{model}_precision'][num])\n",
    "        sum_metrics_loc = float(dataframe[f'{model}_recall'][num])+float(dataframe[f'{model}_molded_loc_precision'][num])\n",
    "        sum_metrics_full = float(dataframe[f'{model}_recall'][num])+float(dataframe[f'{model}_molded_full_precision'][num])\n",
    "        if sum_metrics == 0:\n",
    "            f_score_list.append(float(0))\n",
    "        else:\n",
    "            f_score_list.append((2*float(dataframe[f'{model}_recall'][num])*float(dataframe[f'{model}_precision'][num]))/(sum_metrics))\n",
    "        if sum_metrics_loc == 0:\n",
    "            f_score_list_loc.append(float(0))\n",
    "        else:\n",
    "            f_score_list_loc.append((2*float(dataframe[f'{model}_recall'][num])*float(dataframe[f'{model}_molded_loc_precision'][num]))/(sum_metrics_loc))\n",
    "        if sum_metrics_full == 0:\n",
    "            f_score_list_full.append(float(0))\n",
    "        else:\n",
    "            f_score_list_full.append((2*float(dataframe[f'{model}_recall'][num])*float(dataframe[f'{model}_molded_full_precision'][num]))/(sum_metrics_full))\n",
    "    return f_score_list, f_score_list_loc, f_score_list_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_frame.insert(4,'RAKE_f_score',f_score_metric(metrics_frame, 'RAKE')[0])\n",
    "metrics_frame.insert(5, 'RAKE_m_f_score', f_score_metric(metrics_frame, 'RAKE')[1])\n",
    "metrics_frame.insert(6, 'RAKE_mf_f_score', f_score_metric(metrics_frame, 'RAKE')[2])\n",
    "metrics_frame.insert(11, 'YAKE_f_score', f_score_metric(metrics_frame, 'YAKE')[0])\n",
    "metrics_frame.insert(12, 'YAKE_m_f_score', f_score_metric(metrics_frame, 'YAKE')[1])\n",
    "metrics_frame.insert(13, 'YAKE_mf_f_score', f_score_metric(metrics_frame, 'YAKE')[2])\n",
    "metrics_frame.insert(18, 'textrank_f_score', f_score_metric(metrics_frame, 'textrank')[0])\n",
    "metrics_frame.insert(19, 'textrank_m_f_score', f_score_metric(metrics_frame, 'textrank')[1])\n",
    "metrics_frame.insert(20, 'textrank_mf_f_score', f_score_metric(metrics_frame, 'textrank')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>RAKE_recall</th>\n",
       "      <th>RAKE_precision</th>\n",
       "      <th>RAKE_molded_loc_precision</th>\n",
       "      <th>RAKE_molded_full_precision</th>\n",
       "      <th>RAKE_f_score</th>\n",
       "      <th>RAKE_m_f_score</th>\n",
       "      <th>RAKE_mf_f_score</th>\n",
       "      <th>YAKE_recall</th>\n",
       "      <th>YAKE_precision</th>\n",
       "      <th>YAKE_molded_loc_precision</th>\n",
       "      <th>YAKE_molded_full_precision</th>\n",
       "      <th>YAKE_f_score</th>\n",
       "      <th>YAKE_m_f_score</th>\n",
       "      <th>YAKE_mf_f_score</th>\n",
       "      <th>textrank_recall</th>\n",
       "      <th>textrank_precision</th>\n",
       "      <th>textrank_molded_loc_precision</th>\n",
       "      <th>textrank_molded_full_precision</th>\n",
       "      <th>textrank_f_score</th>\n",
       "      <th>textrank_m_f_score</th>\n",
       "      <th>textrank_mf_f_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.222</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.125</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.571</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RAKE_recall  RAKE_precision  RAKE_molded_loc_precision  RAKE_molded_full_precision  RAKE_f_score  RAKE_m_f_score  RAKE_mf_f_score  YAKE_recall  YAKE_precision  YAKE_molded_loc_precision  YAKE_molded_full_precision  YAKE_f_score  YAKE_m_f_score  YAKE_mf_f_score  textrank_recall  textrank_precision  textrank_molded_loc_precision  textrank_molded_full_precision  textrank_f_score  textrank_m_f_score  textrank_mf_f_score\n",
       "0      0.000          0.000                0.000                       0.000                0.000          0.000           0.000          0.333          0.15                 0.429                       0.176                0.207          0.375           0.231            0.111              0.167                    0.167                           0.167                    0.133              0.133               0.133       \n",
       "1      0.333          0.200                0.250                       0.200                0.250          0.286           0.250          0.000          0.00                 0.000                       0.000                0.000          0.000           0.000            0.000              0.000                    0.000                           0.000                    0.000              0.000               0.000       \n",
       "2      0.167          0.200                0.200                       0.200                0.182          0.182           0.182          0.000          0.00                 0.000                       0.000                0.000          0.000           0.000            0.167              0.083                    0.111                           0.091                    0.111              0.133               0.118       \n",
       "3      0.000          0.000                0.000                       0.000                0.000          0.000           0.000          0.250          0.05                 0.250                       0.091                0.083          0.250           0.133            0.000              0.000                    0.000                           0.000                    0.000              0.000               0.000       \n",
       "4      0.143          0.250                0.250                       0.250                0.182          0.182           0.182          0.143          0.05                 0.143                       0.062                0.074          0.143           0.087            0.000              0.000                    0.000                           0.000                    0.000              0.000               0.000       \n",
       "5      0.333          0.429                0.429                       0.429                0.375          0.375           0.375          0.111          0.05                 1.000                       0.083                0.069          0.200           0.095            0.111              0.091                    0.100                           0.091                    0.100              0.105               0.100       \n",
       "6      0.000          0.000                0.000                       0.000                0.000          0.000           0.000          0.167          0.05                 0.143                       0.071                0.077          0.154           0.100            0.000              0.000                    0.000                           0.000                    0.000              0.000               0.000       \n",
       "7      0.000          0.000                0.000                       0.000                0.000          0.000           0.000          0.333          0.15                 0.500                       0.250                0.207          0.400           0.286            0.000              0.000                    0.000                           0.000                    0.000              0.000               0.000       \n",
       "8      0.000          0.000                0.000                       0.000                0.000          0.000           0.000          0.571          0.20                 0.500                       0.400                0.296          0.533           0.471            0.143              0.167                    1.000                           0.200                    0.154              0.250               0.167       \n",
       "9      0.222          1.000                1.000                       1.000                0.364          0.364           0.364          0.111          0.05                 0.125                       0.100                0.069          0.118           0.105            0.000              0.000                    0.000                           0.000                    0.000              0.000               0.000       \n",
       "10     0.000          0.000                0.000                       0.000                0.000          0.000           0.000          0.167          0.05                 1.000                       0.125                0.077          0.286           0.143            0.500              0.214                    0.250                           0.231                    0.300              0.333               0.316       \n",
       "11     0.125          1.000                1.000                       1.000                0.222          0.222           0.222          0.125          0.05                 0.250                       0.083                0.071          0.167           0.100            0.125              0.071                    0.100                           0.077                    0.091              0.111               0.095       \n",
       "12     0.000          0.000                0.000                       0.000                0.000          0.000           0.000          0.500          0.20                 0.444                       0.364                0.286          0.471           0.421            0.125              0.200                    0.200                           0.200                    0.154              0.154               0.154       \n",
       "13     0.167          0.500                0.500                       0.500                0.250          0.250           0.250          0.167          0.05                 0.500                       0.125                0.077          0.250           0.143            0.167              0.100                    0.143                           0.111                    0.125              0.154               0.133       \n",
       "14     0.143          0.125                0.143                       0.143                0.133          0.143           0.143          0.286          0.10                 0.400                       0.143                0.148          0.333           0.190            0.143              0.071                    0.077                           0.071                    0.095              0.100               0.095       \n",
       "15     0.000          0.000                0.000                       0.000                0.000          0.000           0.000          0.250          0.05                 0.111                       0.071                0.083          0.154           0.111            0.500              0.200                    0.286                           0.222                    0.286              0.364               0.308       \n",
       "16     0.167          0.167                0.500                       0.167                0.167          0.250           0.167          0.333          0.10                 0.222                       0.118                0.154          0.267           0.174            0.000              0.000                    0.000                           0.000                    0.000              0.000               0.000       \n",
       "17     0.571          0.571                0.667                       0.667                0.571          0.615           0.615          0.000          0.00                 0.000                       0.000                0.000          0.000           0.000            0.000              0.000                    0.000                           0.000                    0.000              0.000               0.000       \n",
       "18     0.000          0.000                0.000                       0.000                0.000          0.000           0.000          0.600          0.15                 0.333                       0.231                0.240          0.429           0.333            0.000              0.000                    0.000                           0.000                    0.000              0.000               0.000       "
      ]
     },
     "execution_count": 1412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как...красиво. Но не очень информативно. Найдем средний результат каждой модели на каждом сете данных и оформим как процент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_stats = pd.DataFrame({'metric': metrics_frame.columns.to_list(),\n",
    "                             'score(%)': [round(x*100,2) for x in metrics_frame.mean().to_list()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAKE_recall</td>\n",
       "      <td>12.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAKE_precision</td>\n",
       "      <td>23.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RAKE_molded_loc_precision</td>\n",
       "      <td>25.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAKE_molded_full_precision</td>\n",
       "      <td>23.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAKE_f_score</td>\n",
       "      <td>14.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RAKE_m_f_score</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RAKE_mf_f_score</td>\n",
       "      <td>14.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YAKE_recall</td>\n",
       "      <td>23.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YAKE_precision</td>\n",
       "      <td>7.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YAKE_molded_loc_precision</td>\n",
       "      <td>33.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>YAKE_molded_full_precision</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>YAKE_f_score</td>\n",
       "      <td>11.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>YAKE_m_f_score</td>\n",
       "      <td>23.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>YAKE_mf_f_score</td>\n",
       "      <td>16.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>textrank_recall</td>\n",
       "      <td>11.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>textrank_precision</td>\n",
       "      <td>7.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>textrank_molded_loc_precision</td>\n",
       "      <td>12.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>textrank_molded_full_precision</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>textrank_f_score</td>\n",
       "      <td>8.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>textrank_m_f_score</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>textrank_mf_f_score</td>\n",
       "      <td>8.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric              score(%)\n",
       "0                      RAKE_recall    12.48 \n",
       "1                   RAKE_precision    23.38 \n",
       "2        RAKE_molded_loc_precision    25.99 \n",
       "3       RAKE_molded_full_precision    23.97 \n",
       "4                     RAKE_f_score    14.19 \n",
       "5                   RAKE_m_f_score    15.10 \n",
       "6                  RAKE_mf_f_score    14.47 \n",
       "7                      YAKE_recall    23.41 \n",
       "8                   YAKE_precision     7.89 \n",
       "9        YAKE_molded_loc_precision    33.42 \n",
       "10      YAKE_molded_full_precision    13.13 \n",
       "11                    YAKE_f_score    11.68 \n",
       "12                  YAKE_m_f_score    23.83 \n",
       "13                 YAKE_mf_f_score    16.44 \n",
       "14                 textrank_recall    11.01 \n",
       "15              textrank_precision     7.18 \n",
       "16   textrank_molded_loc_precision    12.81 \n",
       "17  textrank_molded_full_precision     7.69 \n",
       "18                textrank_f_score     8.15 \n",
       "19              textrank_m_f_score     9.67 \n",
       "20             textrank_mf_f_score     8.52 "
      ]
     },
     "execution_count": 1414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "что же мы видим?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- молды по полному сету частеречных сочетаний незначительно повышают точность и ф-число и не меняют полноту\n",
    "- молд по локальному сету частеречных сочетаний значительно повышает точность -> и повышает ф-число\n",
    "- максимальная достигнутая точность: УАКЕ на локальном сете (33.42%); минимальная - textrank без молда (7.18%)\n",
    "- максимальная достигнутая полнота: УАКЕ (23.41%); минимальная - textrank (11.01%)\n",
    "- максимальное ф-число: УАКЕ на локальном сете (23.83%); минимальное - textrank без молда (8.15%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "чтобы нам было удобнее на это все смотреть, сделаем себе подобие матрицы ошибок для каждой из моделей, которые чем-то отличились - в хорошую или в плохую сторону."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "research_frame = data[['gold_standard' , 'YAKE_molded_loc' , 'textrank_molded_loc', 'RAKE_molded_loc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>правда</th>\n",
       "      <th>лишнее</th>\n",
       "      <th>не выделено</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{innovation}</td>\n",
       "      <td>{standpoint, platform use, inter, compress ant...</td>\n",
       "      <td>{outcome, innovation input, digital, innovatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{}</td>\n",
       "      <td>{publish, integrate, author focus, study, rese...</td>\n",
       "      <td>{information technology, innovation, literatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{cooperation}</td>\n",
       "      <td>{base, incumbent, questionnaire, use, factor, ...</td>\n",
       "      <td>{incumbent firm, start-up cooperation, coopera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{}</td>\n",
       "      <td>{framework, accord, digital transformation, pr...</td>\n",
       "      <td>{business process, innovation, digital change,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{}</td>\n",
       "      <td>{use}</td>\n",
       "      <td>{innovation practice, innovation ecosystem, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{digiware}</td>\n",
       "      <td>{include, recognise, business, technology deve...</td>\n",
       "      <td>{farm management, digital innovation, advisory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{}</td>\n",
       "      <td>{contribute, theory, rapid development, status...</td>\n",
       "      <td>{ground theory, in-depth interview, internet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{}</td>\n",
       "      <td>{academia, routine, clinical practicality, pra...</td>\n",
       "      <td>{pet, ddmc, real-time, motion correction, real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{communication technology}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{e-school project, computer literacy, informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{digital intervention, low resource set, menta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{autonomy, mhealth, ethic}</td>\n",
       "      <td>{medical, health, uncritical, ethical, world, ...</td>\n",
       "      <td>{empowerment, ethical issue, ethical research}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{healthcare}</td>\n",
       "      <td>{face, policymaker, health, datum, sector, act...</td>\n",
       "      <td>{innovation, europe, eu, healthcare provision,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{big datum}</td>\n",
       "      <td>{information circulate, drive, deluge, science}</td>\n",
       "      <td>{automation, technological field, field theory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{empowerment}</td>\n",
       "      <td>{empower, citizen, nonprofit, technology, part...</td>\n",
       "      <td>{social innovation, unemployment, participatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{incumbent}</td>\n",
       "      <td>{innovation, include, author, provide, datum, ...</td>\n",
       "      <td>{strategic response, incumbent firm, digital i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{innovation, crowdsource}</td>\n",
       "      <td>{initiative, paper, field, model, level}</td>\n",
       "      <td>{digital innovation ecosystem, management field}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{}</td>\n",
       "      <td>{innovation outcome}</td>\n",
       "      <td>{knowledge recombinant intensity, patent inven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{}</td>\n",
       "      <td>{innovation, diverse, digital, thought, qualit...</td>\n",
       "      <td>{coordination, boundary-spanning tool, knowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{}</td>\n",
       "      <td>{operating, paper discuss, customer}</td>\n",
       "      <td>{fuel loyalty program, operating model, digita...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              правда                                 лишнее                                          не выделено                    \n",
       "0                 {innovation}  {standpoint, platform use, inter, compress ant...  {outcome, innovation input, digital, innovatio...\n",
       "1                           {}  {publish, integrate, author focus, study, rese...  {information technology, innovation, literatur...\n",
       "2                {cooperation}  {base, incumbent, questionnaire, use, factor, ...  {incumbent firm, start-up cooperation, coopera...\n",
       "3                           {}  {framework, accord, digital transformation, pr...  {business process, innovation, digital change,...\n",
       "4                           {}                                              {use}  {innovation practice, innovation ecosystem, di...\n",
       "5                   {digiware}  {include, recognise, business, technology deve...  {farm management, digital innovation, advisory...\n",
       "6                           {}  {contribute, theory, rapid development, status...  {ground theory, in-depth interview, internet, ...\n",
       "7                           {}  {academia, routine, clinical practicality, pra...  {pet, ddmc, real-time, motion correction, real...\n",
       "8   {communication technology}                                                 {}  {e-school project, computer literacy, informat...\n",
       "9                           {}                                                 {}  {digital intervention, low resource set, menta...\n",
       "10  {autonomy, mhealth, ethic}  {medical, health, uncritical, ethical, world, ...     {empowerment, ethical issue, ethical research}\n",
       "11                {healthcare}  {face, policymaker, health, datum, sector, act...  {innovation, europe, eu, healthcare provision,...\n",
       "12                 {big datum}    {information circulate, drive, deluge, science}  {automation, technological field, field theory...\n",
       "13               {empowerment}  {empower, citizen, nonprofit, technology, part...  {social innovation, unemployment, participatio...\n",
       "14                 {incumbent}  {innovation, include, author, provide, datum, ...  {strategic response, incumbent firm, digital i...\n",
       "15   {innovation, crowdsource}           {initiative, paper, field, model, level}   {digital innovation ecosystem, management field}\n",
       "16                          {}                               {innovation outcome}  {knowledge recombinant intensity, patent inven...\n",
       "17                          {}  {innovation, diverse, digital, thought, qualit...  {coordination, boundary-spanning tool, knowled...\n",
       "18                          {}               {operating, paper discuss, customer}  {fuel loyalty program, operating model, digita..."
      ]
     },
     "execution_count": 1416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_textrank = []\n",
    "FP_textrank = []\n",
    "FN_textrank = []\n",
    "\n",
    "for num in range(len(research_frame)):\n",
    "    TP_textrank.append(set(research_frame['gold_standard'][num])&set(research_frame['textrank_molded_loc'][num]))\n",
    "    FP_textrank.append(set(research_frame['textrank_molded_loc'][num])-set(research_frame['gold_standard'][num]))\n",
    "    FN_textrank.append(set(research_frame['gold_standard'][num])-set(research_frame['textrank_molded_loc'][num]))\n",
    "\n",
    "confusion_frame_textrank = pd.DataFrame({'правда': TP_textrank,\n",
    "                                'лишнее': FP_textrank,\n",
    "                                'не выделено': FN_textrank})\n",
    "\n",
    "confusion_frame_textrank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "что ж, обладатель минимальных значений по всем трем метрикам - textrank без молда. Посмотрим, что у него не так.\n",
    "- слишком сильно любит однословные теговые блоки\n",
    "- в принципе неплох, но при любой возможности использует глаголы\n",
    "- есть вероятность, что теггеру мешает маленький размер наших единиц. У английского языка непросто догадаться о части речи многих слов без контекста, а в ключевом блоке контекст это зачастую слово-два, если повезет. Вот он и не справляется с тем, чтобы все глаголы и даже прилагательные выкинуть. Но надо покрутить молд - потыкать, правильно ли он с этой моделью работает, потому что прилагательные явно не должны проходить фильтрацию, как и слово integrate там, где глаголов в молде вообще нет...\n",
    "- похоже, не видит слов с дефисами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>правда</th>\n",
       "      <th>лишнее</th>\n",
       "      <th>не выделено</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{business process, digital innovation, innovat...</td>\n",
       "      <td>{issue accord, issue paper, digital technology...</td>\n",
       "      <td>{innovation, outcome, innovation input, digita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{}</td>\n",
       "      <td>{author focus, support innovation, group level...</td>\n",
       "      <td>{information technology, innovation, literatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{cooperation, start-up performance, incumbent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{business process}</td>\n",
       "      <td>{process maturity, innovation partner, innovat...</td>\n",
       "      <td>{innovation, digital change, cooperative model}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{open innovation}</td>\n",
       "      <td>{incubator characterise, government developmen...</td>\n",
       "      <td>{innovation practice, innovation ecosystem, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{farm adviser}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{farm management, digiware, digital innovation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{public welfare}</td>\n",
       "      <td>{internet platform, welfare project, welfare o...</td>\n",
       "      <td>{ground theory, in-depth interview, internet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{hardware-driven motion correction, data-drive...</td>\n",
       "      <td>{medical physics integrate, real-time acquisit...</td>\n",
       "      <td>{pet, ddmc, real-time, real-time ddmc, data-dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{computer literacy, communication technology, ...</td>\n",
       "      <td>{mature school, theoretical review, school pro...</td>\n",
       "      <td>{informatic curriculum, digitally mature schoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{mental health care}</td>\n",
       "      <td>{low resource setting, digital intervention su...</td>\n",
       "      <td>{digital intervention, low resource set, menta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{ethical issue}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{autonomy, empowerment, mhealth, ethic, ethica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{health datum}</td>\n",
       "      <td>{mobilise health, datum offer, mobilise datum}</td>\n",
       "      <td>{innovation, europe, eu, healthcare provision,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{journalistic field, big datum, technological ...</td>\n",
       "      <td>{datum deluge, field today, information circul...</td>\n",
       "      <td>{automation, digital innovation, technology, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{technology design}</td>\n",
       "      <td>{nonprofit organization}</td>\n",
       "      <td>{empowerment, social innovation, unemployment,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{digital innovation, business model}</td>\n",
       "      <td>{source industry, model change, mobilise busin...</td>\n",
       "      <td>{incumbent, strategic response, incumbent firm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{digital innovation ecosystem}</td>\n",
       "      <td>{implement crowdsource, model complement, issu...</td>\n",
       "      <td>{innovation, crowdsource, management field}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{knowledge recombinant intensity, knowledge re...</td>\n",
       "      <td>{knowledge recombinant effort, influence innov...</td>\n",
       "      <td>{information technology, it, patent invention,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{boundary-spanning tool, coordination, cross-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{operating model, fuel loyalty program, loyalt...</td>\n",
       "      <td>{oil company, loyalty program, customer power ...</td>\n",
       "      <td>{digital innovation, slpp}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         правда                                             лишнее                                          не выделено                    \n",
       "0   {business process, digital innovation, innovat...  {issue accord, issue paper, digital technology...  {innovation, outcome, innovation input, digita...\n",
       "1                                                  {}  {author focus, support innovation, group level...  {information technology, innovation, literatur...\n",
       "2                                                  {}                                                 {}  {cooperation, start-up performance, incumbent ...\n",
       "3                                  {business process}  {process maturity, innovation partner, innovat...    {innovation, digital change, cooperative model}\n",
       "4                                   {open innovation}  {incubator characterise, government developmen...  {innovation practice, innovation ecosystem, di...\n",
       "5                                      {farm adviser}                                                 {}  {farm management, digiware, digital innovation...\n",
       "6                                    {public welfare}  {internet platform, welfare project, welfare o...  {ground theory, in-depth interview, internet, ...\n",
       "7   {hardware-driven motion correction, data-drive...  {medical physics integrate, real-time acquisit...  {pet, ddmc, real-time, real-time ddmc, data-dr...\n",
       "8   {computer literacy, communication technology, ...  {mature school, theoretical review, school pro...  {informatic curriculum, digitally mature schoo...\n",
       "9                                {mental health care}  {low resource setting, digital intervention su...  {digital intervention, low resource set, menta...\n",
       "10                                    {ethical issue}                                                 {}  {autonomy, empowerment, mhealth, ethic, ethica...\n",
       "11                                     {health datum}     {mobilise health, datum offer, mobilise datum}  {innovation, europe, eu, healthcare provision,...\n",
       "12  {journalistic field, big datum, technological ...  {datum deluge, field today, information circul...  {automation, digital innovation, technology, d...\n",
       "13                                {technology design}                           {nonprofit organization}  {empowerment, social innovation, unemployment,...\n",
       "14               {digital innovation, business model}  {source industry, model change, mobilise busin...  {incumbent, strategic response, incumbent firm...\n",
       "15                     {digital innovation ecosystem}  {implement crowdsource, model complement, issu...        {innovation, crowdsource, management field}\n",
       "16  {knowledge recombinant intensity, knowledge re...  {knowledge recombinant effort, influence innov...  {information technology, it, patent invention,...\n",
       "17                                                 {}                                                 {}  {boundary-spanning tool, coordination, cross-d...\n",
       "18  {operating model, fuel loyalty program, loyalt...  {oil company, loyalty program, customer power ...                         {digital innovation, slpp}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TP_YAKE_molded_loc = []\n",
    "FP_YAKE_molded_loc = []\n",
    "FN_YAKE_molded_loc = []\n",
    "\n",
    "for num in range(len(research_frame)):\n",
    "    TP_YAKE_molded_loc.append(set(research_frame['gold_standard'][num])&set(research_frame['YAKE_molded_loc'][num]))\n",
    "    FP_YAKE_molded_loc.append(set(research_frame['YAKE_molded_loc'][num])-set(research_frame['gold_standard'][num]))\n",
    "    FN_YAKE_molded_loc.append(set(research_frame['gold_standard'][num])-set(research_frame['YAKE_molded_loc'][num]))\n",
    "\n",
    "confusion_frame_YAKE_molded_loc = pd.DataFrame({'правда': TP_YAKE_molded_loc,\n",
    "                                'лишнее': FP_YAKE_molded_loc,\n",
    "                                'не выделено': FN_YAKE_molded_loc})\n",
    "\n",
    "display(confusion_frame_YAKE_molded_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "наш чемпион - УАКЕ с локальным молдом! Действительно хорош.\n",
    "- периодически даже не выделяет лишнего! действительно мало лишнего выделяет - правда, сочетает это с тем, что вообще ничего не выделяет.\n",
    "- плачет каждый раз, когда длина тега меньше трех. Героически выделил ключевые блоки из двух слов, ключевые блоки из одного слова гордо игнорирует.\n",
    "- спокойно относится к дефисам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "давайте хоть глянем, чем там РАКЕ занимался..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>правда</th>\n",
       "      <th>лишнее</th>\n",
       "      <th>не выделено</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{}</td>\n",
       "      <td>{digital technology, purpose}</td>\n",
       "      <td>{innovation, outcome, innovation input, digita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{innovation}</td>\n",
       "      <td>{topic, group level, role}</td>\n",
       "      <td>{information technology, literature review}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{cooperation behavior}</td>\n",
       "      <td>{start-, use, build, performance}</td>\n",
       "      <td>{incumbent firm, start-up cooperation, coopera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{}</td>\n",
       "      <td>{study, change, use, digitalise, model, relati...</td>\n",
       "      <td>{business process, innovation, digital change,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{startup}</td>\n",
       "      <td>{industry 4, brazil, collaboration}</td>\n",
       "      <td>{innovation practice, innovation ecosystem, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{farm adviser, digital innovation, digiware}</td>\n",
       "      <td>{recognise, engage, service, digital tool}</td>\n",
       "      <td>{farm management, advisory service, agricultur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{}</td>\n",
       "      <td>{internet platform, integration}</td>\n",
       "      <td>{ground theory, in-depth interview, internet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{}</td>\n",
       "      <td>{opportunity, development}</td>\n",
       "      <td>{pet, ddmc, real-time, motion correction, real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{communication technology, e-school project, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{digital technology, mental health}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{digital intervention, low resource set, menta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{}</td>\n",
       "      <td>{reference}</td>\n",
       "      <td>{autonomy, empowerment, ethical issue, mhealth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{europe}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{innovation, eu, healthcare provision, coopera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{automation, field theory, technological field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{technology design}</td>\n",
       "      <td>{design}</td>\n",
       "      <td>{empowerment, social innovation, unemployment,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{dts}</td>\n",
       "      <td>{paper, source industry, industry, build, resp...</td>\n",
       "      <td>{incumbent, strategic response, incumbent firm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{}</td>\n",
       "      <td>{review, activity, propose, element, organisat...</td>\n",
       "      <td>{innovation, crowdsource, management field, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{innovation process}</td>\n",
       "      <td>{patent quantity}</td>\n",
       "      <td>{knowledge recombinant intensity, patent inven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{boundary-spanning tool, coordination, knowled...</td>\n",
       "      <td>{literature, digital}</td>\n",
       "      <td>{digital innovation, serious game, knowledge d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{operating model, digital innovation, slpp, fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         правда                                             лишнее                                          не выделено                    \n",
       "0                                                  {}                      {digital technology, purpose}  {innovation, outcome, innovation input, digita...\n",
       "1                                        {innovation}                         {topic, group level, role}        {information technology, literature review}\n",
       "2                              {cooperation behavior}                  {start-, use, build, performance}  {incumbent firm, start-up cooperation, coopera...\n",
       "3                                                  {}  {study, change, use, digitalise, model, relati...  {business process, innovation, digital change,...\n",
       "4                                           {startup}                {industry 4, brazil, collaboration}  {innovation practice, innovation ecosystem, di...\n",
       "5        {farm adviser, digital innovation, digiware}         {recognise, engage, service, digital tool}  {farm management, advisory service, agricultur...\n",
       "6                                                  {}                   {internet platform, integration}  {ground theory, in-depth interview, internet, ...\n",
       "7                                                  {}                         {opportunity, development}  {pet, ddmc, real-time, motion correction, real...\n",
       "8                                                  {}                                                 {}  {communication technology, e-school project, d...\n",
       "9                 {digital technology, mental health}                                                 {}  {digital intervention, low resource set, menta...\n",
       "10                                                 {}                                        {reference}  {autonomy, empowerment, ethical issue, mhealth...\n",
       "11                                           {europe}                                                 {}  {innovation, eu, healthcare provision, coopera...\n",
       "12                                                 {}                                                 {}  {automation, field theory, technological field...\n",
       "13                                {technology design}                                           {design}  {empowerment, social innovation, unemployment,...\n",
       "14                                              {dts}  {paper, source industry, industry, build, resp...  {incumbent, strategic response, incumbent firm...\n",
       "15                                                 {}  {review, activity, propose, element, organisat...  {innovation, crowdsource, management field, di...\n",
       "16                               {innovation process}                                  {patent quantity}  {knowledge recombinant intensity, patent inven...\n",
       "17  {boundary-spanning tool, coordination, knowled...                              {literature, digital}  {digital innovation, serious game, knowledge d...\n",
       "18                                                 {}                                                 {}  {operating model, digital innovation, slpp, fu..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TP_RAKE_molded_loc = []\n",
    "FP_RAKE_molded_loc = []\n",
    "FN_RAKE_molded_loc = []\n",
    "\n",
    "for num in range(len(research_frame)):\n",
    "    TP_RAKE_molded_loc.append(set(research_frame['gold_standard'][num])&set(research_frame['RAKE_molded_loc'][num]))\n",
    "    FP_RAKE_molded_loc.append(set(research_frame['RAKE_molded_loc'][num])-set(research_frame['gold_standard'][num]))\n",
    "    FN_RAKE_molded_loc.append(set(research_frame['gold_standard'][num])-set(research_frame['RAKE_molded_loc'][num]))\n",
    "\n",
    "confusion_frame_RAKE_molded_loc = pd.DataFrame({'правда': TP_RAKE_molded_loc,\n",
    "                                'лишнее': FP_RAKE_molded_loc,\n",
    "                                'не выделено': FN_RAKE_molded_loc})\n",
    "\n",
    "display(confusion_frame_RAKE_molded_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тоже обладающий неплохими показателями метрик РАКЕ с локальным молдом! посмотрим, что он делает.\n",
    "- РАКЕ плохо справляется с дефисами - он их все-таки считает поводом разбить слово. Возможно, у него вшит собственный механизм разбивки-токенизации, который решает это все убрать; тем не менее, один раз с дефисом он справился (17) - не опознал слово или его составляющие и оставил в покое?\n",
    "- выкидывать научился в основном прилагательные, с существительными и глаголами все еще путается - но это английский язык, что тут поделаешь. Это надо деление на части речи у спайси покрутить, или в наши молды потыкать, как и у УАКЕ\n",
    "- действительно не любит выделять по три слова в ключевом блоке.\n",
    "- сложные цифры (4.0) ему тоже не нравятся - это тоже указывает в сторону вшитого токенизатора со своими правилами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "что исправить, чтобы все стало лучше?\n",
    "- для РАКЕ: добиться того, чтобы он выделял ключевые блоки с большей длиной и не крутился вечно вокруг однословных - впрочем, возможно, это у нас маленькие кусочки текстов и мало токенов; убедить его не токенизировать по дефисам и вообще дополнительно не токенизировать\n",
    "- для УАКЕ: ничего, он умничка, чмок в лобик\n",
    "- для textrank: узнать, что же там происходит с частеречным делением, что мешает молду фильтровать у него вечные глаголы-прилагательные; тоже как-то пихнуть его в сторону более длинных ключевых блоков - возможно, присваивать более длинным блокам чуточку большие веса? Не факт, что это технически выполнимо, и если даже и да, нужно будет очень точно определить коэффициент домножения весов, чтобы он не начал компульсивно собирать все длинные цепочки, что можно придумать.\n",
    "\n",
    "+ для всех: возможно, деление на части речи стоит производить еще когда текст не очищен и не лемматизирован. Куда-то туда можно воткнуть этот этап; впрочем, он особо не поможет, когда моделькам придется расставлять части речи своих кандидатов - у кандидатов-то контекста нет. Можно, например, для каждого кандидата искать его же в изначальном тексте содержания и вытаскивать часть речи оттуда - там у него еще есть полный контекст."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
